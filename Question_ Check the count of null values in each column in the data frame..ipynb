{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdb1b3c-5689-428b-a7c0-1e08f3f37c94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employee = [(1,'Sagar',23),\n",
    "            (2,None,34),\n",
    "            (None,'John',46),\n",
    "            (5,'Alex',None),\n",
    "            (4,'Alice',None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed3de7d2-ae90-4ee5-a89b-1be645a53662",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employee_schema = 'emp_id int,name string,age int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c8bd43d-6d83-44c9-81e1-f6577e208cc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df = spark.createDataFrame(employee , employee_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b84606-9425-4be8-ba18-bba062d55991",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+\n|emp_id| name| age|\n+------+-----+----+\n|     1|Sagar|  23|\n|     2| null|  34|\n|  null| John|  46|\n|     5| Alex|null|\n|     4|Alice|null|\n+------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81405808-7d33-4056-8638-da61afb682f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,count,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f5d4bb-e39e-4986-9a0c-4e084b706562",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = emp_df.select([count(when(col(i).isNull(),1)).alias(i) for i in emp_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4edbb49-cfaf-4f63-bc53-fbe11ebd9612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+\n|emp_id|name|age|\n+------+----+---+\n|     1|   1|  2|\n+------+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Question: Check the count of null values in each column in the data frame.",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
